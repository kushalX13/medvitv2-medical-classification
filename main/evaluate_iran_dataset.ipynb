{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import transforms\n",
    "\n",
    "test_transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])\n",
    "])\n",
    "\n",
    "\n",
    "### same transforms used by them\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing neutrophil images: 100%|██████████| 1971/1971 [00:08<00:00, 225.36it/s]\n",
      "Processing lymphocyte images: 100%|██████████| 148/148 [00:00<00:00, 245.66it/s]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from PIL import Image\n",
    "from torchvision import transforms\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Define paths\n",
    "source_dir = '/Users/kushal/2nd SEM classes /Deep learning /Final Project /blood_dataset_external/iran_2_classes/Test-B'\n",
    "output_dir = 'iran_2_classes_preprocessed'\n",
    "\n",
    "# Define image transformations\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor()\n",
    "    # Note: Normalization will be applied later, once the mean and std are determined\n",
    "])\n",
    "\n",
    "# Create output directories for each class\n",
    "classes = ['neutrophil', 'lymphocyte']\n",
    "for cls in classes:\n",
    "    os.makedirs(os.path.join(output_dir, cls), exist_ok=True)\n",
    "\n",
    "# Process and save images\n",
    "for cls in classes:\n",
    "    class_dir = os.path.join(source_dir, cls)\n",
    "    output_class_dir = os.path.join(output_dir, cls)\n",
    "    if not os.path.isdir(class_dir):\n",
    "        print(f\"Directory for class '{cls}' not found in source directory.\")\n",
    "        continue\n",
    "    for img_name in tqdm(os.listdir(class_dir), desc=f\"Processing {cls} images\"):\n",
    "        img_path = os.path.join(class_dir, img_name)\n",
    "        try:\n",
    "            # Open and preprocess the image\n",
    "            image = Image.open(img_path).convert('RGB')\n",
    "            image = transform(image)\n",
    "            \n",
    "            # Save the preprocessed image\n",
    "            save_path = os.path.join(output_class_dir, img_name)\n",
    "            # Convert tensor back to PIL Image for saving\n",
    "            image_pil = transforms.ToPILImage()(image)\n",
    "            image_pil.save(save_path)\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing {img_name}: {e}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## load data - iran \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.datasets import ImageFolder\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "data_dir = '/Users/kushal/2nd SEM classes /Deep learning /Final Project /MedViTV2/iran_2_classes_preprocessed'  \n",
    "\n",
    "iran_dataset = ImageFolder(root=data_dir, transform=test_transform)\n",
    "\n",
    "iran_loader = DataLoader(iran_dataset, batch_size=32, shuffle=False, num_workers=4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mps\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "device = torch.device('mps')\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# loading pre trained model "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from MedViT import MedViT_tiny  # Ensure this import matches your project structure\n",
    "\n",
    "# Instantiate the model with the appropriate number of classes\n",
    "model = MedViT_tiny(num_classes=2)  # Adjust num_classes as needed\n",
    "\n",
    "# Load the checkpoint with weights_only=False\n",
    "checkpoint_path = '/Users/kushal/2nd SEM classes /Deep learning /Final Project /MedViTV2/checkpoints/bloodmnist_MedViT_small.json'  # Replace with your actual path\n",
    "state_dict = torch.load(checkpoint_path, map_location='cpu', weights_only=False)\n",
    "\n",
    "# Load the state_dict into the model\n",
    "model.load_state_dict(state_dict)\n",
    "\n",
    "# Set the model to evaluation mode\n",
    "model.eval()\n",
    "model.to(device)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "medvitv2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
